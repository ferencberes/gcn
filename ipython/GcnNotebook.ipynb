{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time, sys, os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../python/\")\n",
    "import preprocessing as pp\n",
    "import baseline_utils as bu\n",
    "import gcn_utils as gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gcn.utils import *\n",
    "from gcn.models import GCN, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../pipelines/GcnProject.json\",sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_id = ph.get(\"dataset_id\")\n",
    "label_type = ph.get(\"label_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_folder = \"blended\" if label_type == \"binary\" else label_type\n",
    "print(label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_type = ph.get(\"split_type\")\n",
    "train_ratio = ph.get(\"train_ratio\")\n",
    "split_id = \"%s_%.2f\" % (split_type, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset_id not in ['cora', 'citeseer', 'pubmed']:\n",
    "    preprocessed_dir = \"%s/data/%s/%s/%s/%s\" % (ph.get(\"experiment_dir\"), dataset_id, pp.get_experiment_dir(ph),split_id,label_folder)\n",
    "    preprocessed_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('dataset', dataset_id, 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')  # 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset_id in ['cora', 'citeseer', 'pubmed']:\n",
    "    input_pref = \"../gcn/data\"\n",
    "else:\n",
    "    input_pref = preprocessed_dir\n",
    "print(input_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset,input_prefix=input_pref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = preprocess_features(features, norm_type = \"col\" if dataset_id == \"15o\" else \"row\")\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix: Stored as a sparse matrix in a dict\n",
    "   * coordinates\n",
    "   * values for coordinates\n",
    "   * shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(features[0].shape)\n",
    "print(features[1].shape)\n",
    "print(features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels: are onehot encoded\n",
    "\n",
    "The number of columns is the number of different groups in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the training data only 20 entity is revealed from each group (for [Cora](https://relational.fit.cvut.cz/dataset/CORA) citiation network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(np.sum(y_train,axis=0))\n",
    "print(np.sum(y_test,axis=0))\n",
    "print(np.sum(y_val,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "boolean vectors which indicate where are the train, validation and test records in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gcn(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS):\n",
    "    accuracies = []\n",
    "    if label_type == \"binary\":\n",
    "        for i in range(y_train.shape[1]):\n",
    "            gcn_acc = gu.run(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS, col_idx=i, verbose=False)\n",
    "            accuracies.append(gcn_acc)\n",
    "    else:\n",
    "        gcn_acc = gu.run(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS)\n",
    "        accuracies.append(gcn_acc)\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = run_gcn(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS)\n",
    "gcn_acc = accuracies.mean(axis=0)\n",
    "print(gcn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: baseline models should also be computed for binary label_type properly!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd_acc_arr = np.array([bu.baseline_predict(y_train, y_test, y_val, train_mask, test_mask, val_mask) for i in range(num_samples)])\n",
    "rnd_acc = list(rnd_acc_arr.mean(axis=0))\n",
    "print(rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted random prediction based on total training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_file = \"%s/ind.%s.ally\" % (input_pref,dataset_id)\n",
    "print(bin_file)\n",
    "w_rnd_acc_arr = np.array([bu.baseline_predict(y_train, y_test, y_val, train_mask, test_mask, val_mask, bin_file_path=bin_file) for i in range(num_samples)])\n",
    "w_rnd_acc = list(w_rnd_acc_arr.mean(axis=0))\n",
    "print(w_rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted random prediction based on partial training set (shown labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_file = \"%s/ind.%s.y\" % (input_pref,dataset_id)\n",
    "print(bin_file)\n",
    "partial_w_rnd_acc_arr = np.array([bu.baseline_predict(y_train, y_test, y_val, train_mask, test_mask, val_mask, bin_file_path=bin_file) for i in range(num_samples)])\n",
    "partial_w_rnd_acc = list(partial_w_rnd_acc_arr.mean(axis=0))\n",
    "print(partial_w_rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write performance to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_dir = \"%s/data/%s/%s/%s/%s\" % (ph.get(\"experiment_dir\"), dataset_id, pp.get_experiment_dir(ph),split_id,label_type)\n",
    "if not os.path.exists(accuracy_dir):\n",
    "    os.makedirs(accuracy_dir)\n",
    "\n",
    "if dataset_id == \"15o\":\n",
    "    with open(\"%s/acc.csv\" % accuracy_dir, \"w+\") as f:\n",
    "        f.write('\"gcn\";%f;%f;%f\\n' % tuple(gcn_acc))\n",
    "        f.write('\"rnd\";%f;%f;%f\\n' % tuple(rnd_acc))\n",
    "        f.write('\"w_rnd\";%f;%f;%f\\n' % tuple(w_rnd_acc))\n",
    "        f.write('\"part_w_rnd\";%f;%f;%f\\n' % tuple(partial_w_rnd_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "   * Train-test split at half time (on first 4 days of 15o)\n",
    "   * Using default parameters of GCN\n",
    "   * For the below experiments **only 'frequency'** feature is used!!! Using any other generated feature ('degree','pagerank','time') would decrease the accuracy to 0.16-0.18 on the testing set.\n",
    "\n",
    "## top_k=3\n",
    "\n",
    "   * timeframe for edge appearence **60 sec**: **te: 0.70515**, tr: 0.75133, val: 0.73000 (2955 nodes, 13796 edges)\n",
    "   * timeframe for edge appearence 100 sec: te: 0.68944, tr: 0.73709, val: 0.72000 (3329 nodes, 21852 edges)\n",
    "   * timeframe for edge appearence 300 sec: te: 0.68245, tr: 0.72145, val: 0.70000 (3835 nodes, 54434 edges)\n",
    "   \n",
    "## top_k=5\n",
    "\n",
    "   * timeframe for edge appearence **60 sec**: **te: 0.67440**, tr: 0.66237, val: 0.68200 (2955 nodes, 13796 edges)\n",
    "   * timeframe for edge appearence 100 sec: te: 0.62205, tr: 0.65703, val: 0.64800 (3329 nodes, 21852 edges)\n",
    "   * timeframe for edge appearence 300 sec: te: 0.60065, tr: 0.64590, val: 0.63400 (3835 nodes, 54434 edges)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}