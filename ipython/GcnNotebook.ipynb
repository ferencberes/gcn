{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time, sys, os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../python/\")\n",
    "import preprocessing as pp\n",
    "import baseline_utils as bu\n",
    "import gcn_utils as gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gcn.utils import *\n",
    "from gcn.models import GCN, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../pipelines/GcnProject.json\",sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_id = ph.get(\"dataset_id\")\n",
    "label_type = ph.get(\"label_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_folder = \"blended\" if label_type == \"binary\" else label_type\n",
    "print(label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_type = ph.get(\"split_type\")\n",
    "train_ratio = ph.get(\"train_ratio\")\n",
    "split_id = \"%s_%.2f\" % (split_type, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset_id not in ['cora', 'citeseer', 'pubmed']:\n",
    "    preprocessed_dir = \"%s/data/%s/%s/%s/%s\" % (ph.get(\"experiment_dir\"), dataset_id, pp.get_experiment_dir(ph),split_id,label_folder)\n",
    "    print(preprocessed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('dataset', dataset_id, 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')  # 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset_id in ['cora', 'citeseer', 'pubmed']:\n",
    "    input_pref = \"../gcn/data\"\n",
    "else:\n",
    "    input_pref = preprocessed_dir\n",
    "print(input_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset,input_prefix=input_pref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = preprocess_features(features, norm_type = \"col\" if dataset_id in [\"15o\",\"occupy\"] else \"row\")\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix: Stored as a sparse matrix in a dict\n",
    "   * coordinates\n",
    "   * values for coordinates\n",
    "   * shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(features[0].shape)\n",
    "print(features[1].shape)\n",
    "print(features[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels: are onehot encoded\n",
    "\n",
    "The number of columns is the number of different groups in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the training data only 20 entity is revealed from each group (for [Cora](https://relational.fit.cvut.cz/dataset/CORA) citiation network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(np.sum(y_train,axis=0))\n",
    "print(np.sum(y_test,axis=0))\n",
    "print(np.sum(y_val,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "boolean vectors which indicate where are the train, validation and test records in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gcn(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS):\n",
    "    accuracies = []\n",
    "    if label_type == \"binary\":\n",
    "        for i in range(y_train.shape[1]):\n",
    "            gcn_acc, _ = gu.run(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS, col_idx=i, verbose=False)\n",
    "            accuracies.append(gcn_acc)\n",
    "    else:\n",
    "        gcn_acc, _ = gu.run(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS)\n",
    "        accuracies.append(gcn_acc)\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = run_gcn(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS)\n",
    "gcn_acc = accuracies.mean(axis=0)\n",
    "print(gcn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Examination of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "acc_vect, preds = gu.run(features, y_train, y_test, y_val, train_mask, test_mask, val_mask, num_supports, support, model_func, FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def get_confusions(pred_arr,label_arr,mask,label_type):\n",
    "    dim = label_arr.shape[1]\n",
    "    masked_preds = pred_arr[mask]\n",
    "    masked_labels = label_arr[mask]\n",
    "    conf_mx = np.zeros((dim,dim))\n",
    "    for k in range(len(masked_labels)):\n",
    "        label_row = masked_labels[k]\n",
    "        pred_row = masked_preds[k]\n",
    "        one_indices = np.argwhere(label_row==1)\n",
    "        one_indices = [item[0] for item in one_indices]\n",
    "        if label_type == \"blended\":\n",
    "            update_blended_confusions(conf_mx, label_row, pred_row, one_indices)\n",
    "        elif label_type == \"onehot\":\n",
    "            update_onehot_confusions(conf_mx, label_row, pred_row, one_indices)\n",
    "        else:\n",
    "            raise RuntimeError(\"Invalid label type!!!\")\n",
    "    return conf_mx\n",
    "\n",
    "def update_blended_confusions(conf_mx, label_row, pred_row, one_indices):\n",
    "    dim = conf_mx.shape[1]\n",
    "    num_one = len(one_indices)\n",
    "    for i in one_indices:\n",
    "        # correct prediction\n",
    "        conf_mx[i,i] += pred_row[i]\n",
    "        # incorrect prediction\n",
    "        for j in range(dim):\n",
    "            if not j in one_indices:\n",
    "                conf_mx[i,j] += pred_row[i] / num_one\n",
    "\n",
    "def update_onehot_confusions(conf_mx, label_row, pred_row, one_indices):\n",
    "    if len(one_indices) != 1:\n",
    "        raise RuntimeError(\"Label cannot contain more than one 1!\")\n",
    "    else:\n",
    "        i = one_indices[0]\n",
    "        j = np.argmax(pred_row)\n",
    "        conf_mx[i,j] += pred_row[j]\n",
    "        \n",
    "def show_confusion_mx(pred_arr,label_arr,mask,label_type):\n",
    "    conf_mx = get_confusions(pred_arr,label_arr,mask,label_type)\n",
    "    sns.heatmap(conf_mx)\n",
    "    print(pd.DataFrame(conf_mx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_confusion_mx(preds,y_test,test_mask,label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUG? : the first row of y_test is all zero! but test_mask is True for this index!!! WHY? for onehot label creation, for blended it is not a problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_baseline(y_train, y_test, y_val, train_mask, test_mask, val_mask, num_samples=5, bin_file_path=None):\n",
    "    labels_arr = None\n",
    "    if bin_file_path != None:\n",
    "        with open(bin_file_path, 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                labels_arr = pkl.load(f, encoding='latin1')\n",
    "            else:\n",
    "                labels_arr = pkl.load(f)\n",
    "    accuracies = []\n",
    "    if label_type == \"binary\":\n",
    "        for i in range(y_train.shape[1]):\n",
    "            tmp_label = np.vstack(labels_arr[i]) if labels_arr != None else None\n",
    "            accuracies += [bu.baseline_predict(y_train, y_test, y_val, train_mask, test_mask, val_mask, label_samples=tmp_label) for i in range(num_samples)]\n",
    "    else:\n",
    "        accuracies += [bu.baseline_predict(y_train, y_test, y_val, train_mask, test_mask, val_mask, label_samples=labels_arr) for i in range(num_samples)]\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd_acc_arr = run_baseline(y_train, y_test, y_val, train_mask, test_mask, val_mask)\n",
    "rnd_acc = list(rnd_acc_arr.mean(axis=0))\n",
    "print(rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted random prediction based on total training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_file = \"%s/ind.%s.ally\" % (input_pref,dataset_id)\n",
    "print(bin_file)\n",
    "w_rnd_acc_arr = run_baseline(y_train, y_test, y_val, train_mask, test_mask, val_mask, bin_file_path=bin_file)\n",
    "w_rnd_acc = list(w_rnd_acc_arr.mean(axis=0))\n",
    "print(w_rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted random prediction based on partial training set (shown labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_file = \"%s/ind.%s.y\" % (input_pref,dataset_id)\n",
    "print(bin_file)\n",
    "partial_w_rnd_acc_arr = run_baseline(y_train, y_test, y_val, train_mask, test_mask, val_mask, bin_file_path=bin_file)\n",
    "partial_w_rnd_acc = list(partial_w_rnd_acc_arr.mean(axis=0))\n",
    "print(partial_w_rnd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write performance to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_dir = \"%s/data/%s/%s/%s/%s\" % (ph.get(\"experiment_dir\"), dataset_id, pp.get_experiment_dir(ph),split_id,label_type)\n",
    "print(accuracy_dir)\n",
    "if not os.path.exists(accuracy_dir):\n",
    "    os.makedirs(accuracy_dir)\n",
    "\n",
    "if dataset_id in [\"15o\",\"occupy\"]:\n",
    "    with open(\"%s/acc.csv\" % accuracy_dir, \"w+\") as f:\n",
    "        f.write('\"gcn\";%f;%f;%f\\n' % tuple(gcn_acc))\n",
    "        f.write('\"rnd\";%f;%f;%f\\n' % tuple(rnd_acc))\n",
    "        f.write('\"w_rnd\";%f;%f;%f\\n' % tuple(w_rnd_acc))\n",
    "        f.write('\"part_w_rnd\";%f;%f;%f\\n' % tuple(partial_w_rnd_acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}